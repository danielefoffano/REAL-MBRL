class Params:
    ADVERSARIAL = False
    MODEL_BASED = False
    N_ROLLOUTS = 200
    ALPHA = 5e-3                        # learning rate
    MODEL_BATCH_SIZE = 200              # how many batches to divide the roll-out transitions into
    MODEL_EPOCHS = 100                  # how many epochs we want to train model network
    DATASET_SIZE = 1500
    GAMMA = 0.99                        # discount rate
    POLICY_HIDDEN_SIZE = 32             # number of hidden nodes we have in policy
    ADVERSARY_HIDDEN_SIZE = 32          # number of hidden nodes we have in adversary
    MODEL_HIDDEN_SIZE = 256             # number of hidden nodes we have in model
    REW_HIDDEN_SIZE = 64
    CRITIC_HIDDEN_SIZE = 128
    ROLLOUT_LEN = 300                   # Length of rollout to collect data for policy improvement
    ENSEMBLE_SIZE = 3                   # number of models in the ensemble
    EPSILON = 0.6
    TIMESTEPS_PER_BATCH = 20000         # Number of timesteps to run per batch
    N_UPDATES_PER_ITERATION = 5         # Number of times to update actor/critic per iteration
    CLIP = 0.2                          # Clip for PPO
    TOTAL_ITERATIONS = 100
    SAMPLES_FOR_MODEL = 1000            # Number of samples collected to train the model at each iteration
    MODEL_SAMPLES_ROLLOUT_LEN = 1000    # Length of rollouts performed to collect data for model training
    ENV_NAME = 'CartPole-v1'